# Definir el nombre del proyecto
export PROJECT=windy-tiger-410421

# Establecer el proyecto actual en la configuración de gcloud
gcloud config set project $PROJECT

# Crear un directorio llamado "dataflow"
mkdir dataflow

# Cambiar al directorio "dataflow"
cd dataflow

# Copiar archivos desde un bucket de Google Cloud Storage a la carpeta local
gsutil cp -r gs://scripts-windy-tiger-410421 .

# Construir una imagen de Docker llamada "contenedorprueba" desde el Dockerfile en el directorio actual
docker build -t contenedorprueba .

# Ejecutar un contenedor basado en la imagen "contenedorprueba"
docker run contenedorprueba

# Ejecutar un script de Python llamado "pipeline.py" utilizando Dataflow en Google Cloud
python pipeline.py \
  --project=$PROJECT \  # Proyecto de Google Cloud
  --region=us-central1 \  # Región de ejecución
  --runner=DataflowRunner \  # Tipo de runner (Dataflow en este caso)
  --machine_type=e2-standard-2 \  # Tipo de máquina virtual utilizada por Dataflow
  --save_main_session  # Indicar a Dataflow que guarde el estado principal de la sesión
