{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Incremental Load Google Data (Extract, Load, Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook focuses on retrieving and preprocessing Google Maps reviews data using the Apify API. The collected data includes information such as user IDs, place IDs, star ratings, review text, and timestamps. The objective is to clean and structure the data for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect and Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API URL with token\n",
    "api_url = \"https://api.apify.com/v2/actor-tasks/frombini~google-maps-scraper-task/runs/last/dataset/items?token=apify_api_ZE7FMykxbpsHef9FAMxUqF9esYgIGK2LrElm&unwind=reviews&fields=placeId,reviews&omit=textTranslated,publishAt,likesCount,reviewId,reviewUrl,reviewerUrl,reviewerPhotoUrl,reviewerNumberOfReviews,isLocalGuide,rating,reviewImageUrls,reviewContext,reviewDetailedRating,name,responseFromOwnerDate,responseFromOwnerText\"\n",
    "\n",
    "# Make a GET request\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Check the response status\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Print the data (or do whatever you want with it)\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Error in the request: {response.status_code}, {response.text}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "new_data = pd.DataFrame(data=data)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows with missing text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove duplicate rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rename columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.rename(columns={'reviewerId': 'user_id', 'placeId': 'place_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the 'publishedAtDate' column to datetime type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna publishedAtDate a tipo datetime\n",
    "new_data['publishedAtDate'] = pd.to_datetime(new_data['publishedAtDate'])\n",
    "\n",
    "# Extract month, year, and hour\n",
    "new_data['month'] = new_data['publishedAtDate'].dt.month\n",
    "new_data['year'] = new_data['publishedAtDate'].dt.year\n",
    "new_data['hour'] = new_data['publishedAtDate'].dt.hour\n",
    "\n",
    "new_data.drop(columns=['publishedAtDate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define column order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['user_id', 'place_id', 'stars', 'text', 'month', 'year', 'hour']\n",
    "new_data = new_data[column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the 'text' column to lowercase and remove special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Check if the value is a string\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove special characters using regular expressions\n",
    "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "new_data['text'] = new_data['text'].apply(clean_text)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change 'place_id' to 'business_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 'businessId_gmapID' table\n",
    "businessId_gmapID = pd.read_csv(r\"D:\\Datasets_proyecto\\businessId_gmapID.csv\")\n",
    "\n",
    "# Replace 'Sin Valores' in 'place_id' with the value of 'business_id'\n",
    "businessId_gmapID['place_id'] = businessId_gmapID.apply(lambda row: row['business_id'] if row['place_id'] == 'Sin Valores' else row['place_id'], axis=1)\n",
    "\n",
    "# Concatenate based on the 'place_id' column\n",
    "new_data = pd.merge(businessId_gmapID, new_data, on='place_id', how='inner')\n",
    "\n",
    "# Drop the 'place_id' column\n",
    "new_data.drop(columns=['Unnamed: 0', 'place_id'], inplace=True)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo de carga de YELP (Apify) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la API con el token\n",
    "api_url = \"https://api.apify.com/v2/actor-tasks/frombini~yelp-scrap-task/runs/last/dataset/items?token=apify_api_ZE7FMykxbpsHef9FAMxUqF9esYgIGK2LrElm&unwind=review\"\n",
    "\n",
    "# Realiza la solicitud GET\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Verifica el estado de la respuesta\n",
    "if response.status_code == 200:\n",
    "    # Parsea la respuesta JSON\n",
    "    data = response.json()\n",
    "\n",
    "    # Imprime los datos\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Error en la solicitud: {response.status_code}, {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
